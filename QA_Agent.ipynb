{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c53800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 PDFs: ['sample1.pdf', 'sample2.pdf', 'sample3.pdf', 'sample4.pdf', 'sample5.pdf']\n",
      "\n",
      "ðŸ“„ sample1.pdf â†’ What is the conclusion of this paper?\n",
      "There is no specific paper to draw a conclusion from, as the text provides a list of research papers, publications, and seminar proceedings by various authors, including Chattopadhyay S and Singh S. The text does not provide the content or findings of a specific paper, but rather a bibliography of the authors' works. \n",
      "\n",
      "If you could provide the title of a specific paper or more context, I would be happy to try and help you understand the conclusion of that particular paper.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "ðŸ“„ sample2.pdf â†’ Summarize the methodology of this paper.\n",
      "The methodology of this paper involves a two-step approach: \n",
      "\n",
      "1. **Bibliometric analysis**: The authors conducted a bibliometric analysis of 2,223 research articles related to Artificial Intelligence in Education (AIED). This analysis likely involved quantitative methods to examine the publications, citations, and other metrics related to AIED research.\n",
      "\n",
      "2. **Content analysis**: Following the bibliometric analysis, the authors selected 125 papers for a content analysis. This qualitative approach involved a detailed examination of the selected papers to gain insights into the research topics, findings, theories, methodologies, and research contexts within the AIED field.\n",
      "\n",
      "By combining these two methods, the authors aimed to provide a comprehensive understanding of the current state of AIED research and identify future research opportunities.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "ðŸ“„ sample3.pdf â†’ What are the accuracy and F1-score reported in this paper?\n",
      "Neither the accuracy nor the F1-score is reported in this paper. The text appears to be an introduction to quantum computing and does not mention any specific metrics or evaluation results. It seems to be a general overview of the topic, discussing its history, principles, and potential applications.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "ðŸ“„ sample4.pdf â†’ What is the main hypothesis or research objective of this paper?\n",
      "The main hypothesis or research objective of this paper is to propose a generalized method to determine the aggregate interlock stresses using the crack surface directly from 3D scanning, and to investigate the influence of surface roughness on aggregate interlock, particularly for new types of concrete such as high-strength concrete and lightweight aggregate concrete.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "ðŸ“„ sample5.pdf â†’ List the limitations or challenges mentioned in this paper.\n",
      "The limitations or challenges mentioned in this paper are:\n",
      "\n",
      "1. The requirement for a structural core in traditional modular construction, which can be time and resource-intensive.\n",
      "2. The lack of information on using self-supported systems for high-rise prefabricated prefinished volumetric construction (PPVC).\n",
      "3. The challenge of achieving efficient self-supported systems that can replace traditional concrete structural cores.\n",
      "4. The need for improved interconnections between modules in coreless PPVC systems.\n",
      "5. The limitations of traditional construction methods, including lower productivity, lower quality, and slower construction speeds compared to prefabricated prefinished volumetric construction (PPVC).\n",
      "\n",
      "Note that these limitations and challenges are not necessarily inherent to the proposed novel rocking steel interconnection (RSI) system, but rather are mentioned as motivations for the development of this new system.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "Title: The Rise of Quantum Internet Computing\n",
      "Authors: Seng W. Loke\n",
      "Summary: This article highlights quantum Internet computing as referring to\n",
      "distributed quantum computing over the quantum Internet, analogous to\n",
      "(classical) Internet computing involving (classical) distributed computing over\n",
      "the (classical) Internet. Relevant to quantum Internet computing would be areas\n",
      "of study such as quantum protocols for distributed nodes using quantum\n",
      "information for computations, quantum cloud computing, delegated verifiable\n",
      "blind or private computing, non-local gates, and distributed quantum\n",
      "applications, over Internet-scale distances.\n",
      "PDF: http://arxiv.org/pdf/2208.00733v1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Enterprise Document Q&A AI Agent\n",
    "# ==============================\n",
    "\n",
    "# ==============================\n",
    "# 1. Import Libraries\n",
    "# ==============================\n",
    "import os\n",
    "import fitz  # PyMuPDF for PDF reading\n",
    "from groq import Groq, Client\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# ==============================\n",
    "# 2. Initialize Groq LLM Client\n",
    "# ==============================\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))  # Set your Groq API key in environment variables\n",
    "\n",
    "# ==============================\n",
    "# 3. Extract Text from PDFs\n",
    "# ==============================\n",
    "def extract_texts_from_folder(folder_path=\"enterprise_ai_agent/data\"):\n",
    "    pdf_texts = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            with fitz.open(filepath) as doc:\n",
    "                text = \"\"\n",
    "                for page in doc:\n",
    "                    text += page.get_text()\n",
    "                pdf_texts[filename] = text\n",
    "    return pdf_texts\n",
    "\n",
    "# ==============================\n",
    "# 4. Ask LLM a Question\n",
    "# ==============================\n",
    "def ask_llm(question, context):\n",
    "    prompt = f\"\"\"Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Q: {question}\n",
    "A:\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\",  # Active model\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"LLM Error: {e}\"\n",
    "\n",
    "# ==============================\n",
    "# 5. Fetch Papers from ArXiv (Bonus)\n",
    "# ==============================\n",
    "def query_arxiv(search_term, max_results=1):\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=all:{search_term}&start=0&max_results={max_results}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        root = ET.fromstring(r.content)\n",
    "        ns = {\"atom\": \"http://www.w3.org/2005/Atom\", \"arxiv\": \"http://arxiv.org/schemas/atom\"}\n",
    "        papers = []\n",
    "        for entry in root.findall(\"atom:entry\", ns):\n",
    "            title = entry.find(\"atom:title\", ns).text\n",
    "            summary = entry.find(\"atom:summary\", ns).text\n",
    "            authors = [a.find(\"atom:name\", ns).text for a in entry.findall(\"atom:author\", ns)]\n",
    "            pdf_link = entry.find(\"atom:link[@title='pdf']\", ns).attrib['href']\n",
    "            papers.append({\n",
    "                \"title\": title.strip(),\n",
    "                \"summary\": summary.strip(),\n",
    "                \"authors\": authors,\n",
    "                \"pdf_link\": pdf_link\n",
    "            })\n",
    "        return papers\n",
    "    except Exception as e:\n",
    "        return f\"ArXiv API Error: {e}\"\n",
    "\n",
    "# ==============================\n",
    "# 6. Load PDFs\n",
    "# ==============================\n",
    "pdf_texts = extract_texts_from_folder(\"enterprise_ai_agent/data\")\n",
    "print(f\"Loaded {len(pdf_texts)} PDFs: {list(pdf_texts.keys())}\")\n",
    "\n",
    "# ==============================\n",
    "# 7. Assign One Question Per PDF\n",
    "# ==============================\n",
    "questions_per_pdf = {\n",
    "    \"sample1.pdf\": \"What is the conclusion of this paper?\",\n",
    "    \"sample2.pdf\": \"Summarize the methodology of this paper.\",\n",
    "    \"sample3.pdf\": \"What are the accuracy and F1-score reported in this paper?\",\n",
    "    \"sample4.pdf\": \"What is the main hypothesis or research objective of this paper?\",\n",
    "    \"sample5.pdf\": \"List the limitations or challenges mentioned in this paper.\"\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# 8. Ask Questions and Save Results\n",
    "# ==============================\n",
    "output_file = \"qa_results.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc_name, question in questions_per_pdf.items():\n",
    "        if doc_name in pdf_texts:\n",
    "            context = pdf_texts[doc_name][:5000]  # Limit context for LLM\n",
    "            answer = ask_llm(question, context)\n",
    "            result_text = f\"\\nðŸ“„ {doc_name} â†’ {question}\\n{answer}\\n{'-'*60}\\n\"\n",
    "            print(result_text)\n",
    "            f.write(result_text)\n",
    "        else:\n",
    "            not_found_text = f\"\\nðŸ“„ {doc_name} â†’ File not found!\\n{'-'*60}\\n\"\n",
    "            print(not_found_text)\n",
    "            f.write(not_found_text)\n",
    "\n",
    "# ==============================\n",
    "# 9. Optional: ArXiv Query Example\n",
    "# ==============================\n",
    "search_results = query_arxiv(\"quantum computing\", max_results=1)\n",
    "for paper in search_results:\n",
    "    arxiv_text = f\"\\nTitle: {paper['title']}\\nAuthors: {', '.join(paper['authors'])}\\nSummary: {paper['summary']}\\nPDF: {paper['pdf_link']}\\n{'-'*60}\\n\"\n",
    "    print(arxiv_text)\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(arxiv_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7ab68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
